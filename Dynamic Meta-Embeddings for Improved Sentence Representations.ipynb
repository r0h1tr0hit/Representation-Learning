{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLNLP3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aebJ1C_7FitL"
      },
      "source": [
        "# **Representation Learning**\n",
        "\n",
        "### Aim of this work is to learn different types of embeddings such as Word2vec, GloVe and fastText and compare their performance on the sentence classification task.  To learn which embeddings the network prefers for a given problem by predicting a weight for each embedding type.\n",
        "\n",
        "## **Dynamic Meta-Embeddings for Improved Sentence Representations**\n",
        "\n",
        "Dynamic meta-embeddings, a simple yet ef\u0002fective method for the supervised learning of embedding ensembles. The method is to giving networks access to multiple types of embeddings, allowing a network to learn which embeddings it\n",
        "prefers by predicting a weight for each embedding type, optionally depending on the context.\n",
        "\n",
        "## Reference\n",
        "\n",
        "Kiela et. al., Dynamic Meta-Embeddings for Improved Sentence Representations, EMNLP, 2018.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYyaPeuMBzmj",
        "outputId": "b5e40d0f-98bd-4f3a-c55b-a08ed9069e63"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HszrkKxWwUmW"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU, Input, Reshape, Concatenate, Permute, Activation, multiply, Lambda\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.initializers import Constant\n",
        "from keras import Model\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWJMvt6XB8um"
      },
      "source": [
        "positive_data = []\n",
        "\n",
        "file = open('rt-polarity.pos','rb')\n",
        "lines = file.read().decode('utf-8','ignore').splitlines()\n",
        "\n",
        "for l in lines:\n",
        "  positive_data.append(l)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "FuTjElZNOZ7R",
        "outputId": "2e86124d-cdf5-4bc6-b8d0-8596f738ed6a"
      },
      "source": [
        "positive_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . '"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri3YeeK4hlW2"
      },
      "source": [
        "negative_data = []\n",
        "\n",
        "file = open('rt-polarity.neg','rb')\n",
        "lines = file.read().decode('utf-8','ignore').splitlines()\n",
        "\n",
        "for l in lines:\n",
        "  negative_data.append(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKwPQxAcXxAM"
      },
      "source": [
        "# Removing punctuations\n",
        "\n",
        "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~0123456789'''\n",
        "i = 0\n",
        "for sentence in positive_data:\n",
        "  for ele in sentence:\n",
        "    if ele in punctuations:\n",
        "        sentence = sentence.replace(ele, \"\")\n",
        "  positive_data[i] = sentence\n",
        "  i+=1\n",
        "\n",
        "\n",
        "i = 0\n",
        "for sentence in negative_data:\n",
        "  for ele in sentence:\n",
        "    if ele in punctuations:\n",
        "        sentence = sentence.replace(ele, \"\")\n",
        "  negative_data[i] = sentence\n",
        "  i+=1\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U7-ZEO8BYjqM",
        "outputId": "477ee38a-d0b7-4b48-e8ac-f9a46aace470"
      },
      "source": [
        "positive_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the rock is destined to be the st centurys new  conan  and that hes going to make a splash even greater than arnold schwarzenegger  jeanclaud van damme or steven segal  '"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HxB0nzqO949",
        "outputId": "b9909c2e-4d2d-4ab4-de83-d91aa5e6056b"
      },
      "source": [
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-06 09:49:30--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-09-06 09:49:30--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-09-06 09:49:30--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.57MB/s    in 2m 41s  \n",
            "\n",
            "2021-09-06 09:52:11 (5.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4TGqUvpTony",
        "outputId": "e3b121a1-7995-4267-9834-567423e9ea21"
      },
      "source": [
        "# !unzip glove*.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkP2S_clqI0c"
      },
      "source": [
        "train_label = [1]*4500 + [0]*4500\n",
        "test_label = [1]*831 + [0]*831\n",
        "train_label = np.array(train_label)\n",
        "test_label = np.array(test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yTPBeGEtMes",
        "outputId": "789e5343-0205-4d48-a576-17c11dd5a4fc"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcidD_uJIgfu"
      },
      "source": [
        "Using Lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJoOG01LIVVA"
      },
      "source": [
        "pre_positive_data = []\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "  \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for s in positive_data:\n",
        "  l = []\n",
        "  for w in s.split():\n",
        "    w = lemmatizer.lemmatize(w)\n",
        "    l.append(w)\n",
        "  \n",
        "  # pre_data.append(l)\n",
        "  pre_positive_data.append(\" \".join([i for i in l]))\n",
        "\n",
        "\n",
        "pre_negative_data = []\n",
        "  \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for s in negative_data:\n",
        "  l = []\n",
        "  for w in s.split():\n",
        "    w = lemmatizer.lemmatize(w)\n",
        "    l.append(w)\n",
        "  \n",
        "  # pre_data.append(l)\n",
        "  pre_negative_data.append(\" \".join([i for i in l]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lExcADOS80be"
      },
      "source": [
        "train_data = pre_positive_data[:4500] + pre_negative_data[:4500]\n",
        "test_data = pre_positive_data[4500:] + pre_negative_data[4500:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKjs5zRC2apf"
      },
      "source": [
        "train_max_len = max([len(s.split()) for s in train_data])\n",
        "test_max_len = max([len(s.split()) for s in test_data])\n",
        "\n",
        "if train_max_len > test_max_len:\n",
        "  max_len = train_max_len\n",
        "else:\n",
        "  max_len = test_max_len\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4eH_nrI2xZz",
        "outputId": "95d839a1-7fb8-4e40-c39a-d222d0a74029"
      },
      "source": [
        "max_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ7t7UGr9wpw",
        "outputId": "18c9df27-76fb-4eec-b11d-4cb180238f49"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data)\n",
        "sequences = tokenizer.texts_to_sequences(train_data)\n",
        "\n",
        "#pad sequences\n",
        "train_word_index = tokenizer.word_index\n",
        "print(\"number of unique tokens = \", len(train_word_index))\n",
        "\n",
        "\n",
        "\n",
        "train_padded_sequences = pad_sequences(sequences, padding='post', maxlen = max_len)\n",
        "\n",
        "tokenizer.fit_on_texts(test_data)\n",
        "sequences = tokenizer.texts_to_sequences(test_data)\n",
        "\n",
        "#pad sequences\n",
        "test_word_index = tokenizer.word_index\n",
        "print(\"number of unique tokens = \", len(test_word_index))\n",
        "\n",
        "test_padded_sequences = pad_sequences(sequences, padding='post', maxlen = max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unique tokens =  16763\n",
            "number of unique tokens =  18310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWo3VcpMAr6M",
        "outputId": "331ae91b-4d35-4d20-b5ff-4e70d0aab05c"
      },
      "source": [
        "test_padded_sequences[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2,   54,  245,  167,  334,   22,    4,    1,   82,  286,    1,\n",
              "        259, 9102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AizEqAUDoXJ"
      },
      "source": [
        "using glove embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvBQq7Uatrr3"
      },
      "source": [
        "import numpy as np\n",
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "embedding_dim = 300\n",
        "f = open('/content/drive/MyDrive/IISc_Assignment/DLNLP_Assignment3/glove.6B.300d.txt')\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql22ZFUTERb9"
      },
      "source": [
        "unique_words = len(train_word_index) + 1\n",
        "glove_embedding = np.zeros((unique_words, embedding_dim))\n",
        "\n",
        "for word, i in train_word_index.items():\n",
        "  # if i > num_words:\n",
        "  #   continue\n",
        "  if word in embeddings_index:\n",
        "    embedding = embeddings_index[word]\n",
        "\n",
        "  \n",
        "\n",
        "  if embedding is not None:\n",
        "    glove_embedding[i] = embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3YIrJpPHCl_",
        "outputId": "3023967d-ee6f-4c9e-8e85-38f439278a22"
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(unique_words, \n",
        "                            output_dim = embedding_dim,\n",
        "                            weights = [glove_embedding], trainable = False)\n",
        "\n",
        "model.add(embedding_layer)\n",
        "model.add(LSTM(units=32, dropout=0.2, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3o9xG0HExnf",
        "outputId": "2a7409ec-895a-4d1b-8a04-4cb3ae67ac7b"
      },
      "source": [
        "model.fit(train_padded_sequences, train_label, epochs=10, verbose = 1, validation_split= 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "225/225 [==============================] - 20s 73ms/step - loss: 0.6612 - accuracy: 0.6233 - val_loss: 1.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "225/225 [==============================] - 16s 71ms/step - loss: 0.6662 - accuracy: 0.6247 - val_loss: 0.8141 - val_accuracy: 5.5556e-04\n",
            "Epoch 3/10\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.6537 - accuracy: 0.6250 - val_loss: 0.9175 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "225/225 [==============================] - 16s 71ms/step - loss: 0.6232 - accuracy: 0.6251 - val_loss: 0.8252 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5963 - accuracy: 0.6440 - val_loss: 0.9846 - val_accuracy: 0.6039\n",
            "Epoch 6/10\n",
            "225/225 [==============================] - 16s 71ms/step - loss: 0.5559 - accuracy: 0.7132 - val_loss: 0.7177 - val_accuracy: 0.6572\n",
            "Epoch 7/10\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5635 - accuracy: 0.7035 - val_loss: 0.8740 - val_accuracy: 0.4806\n",
            "Epoch 8/10\n",
            "225/225 [==============================] - 16s 72ms/step - loss: 0.5456 - accuracy: 0.7194 - val_loss: 0.6194 - val_accuracy: 0.7778\n",
            "Epoch 9/10\n",
            "225/225 [==============================] - 16s 71ms/step - loss: 0.5221 - accuracy: 0.7403 - val_loss: 0.6860 - val_accuracy: 0.6783\n",
            "Epoch 10/10\n",
            "225/225 [==============================] - 16s 71ms/step - loss: 0.5054 - accuracy: 0.7497 - val_loss: 0.7983 - val_accuracy: 0.5939\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9740558610>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22cSgZgMFc6-",
        "outputId": "6c3eb6ec-da91-4eb4-ac75-cf1487f1aa63"
      },
      "source": [
        "model.evaluate(test_padded_sequences, test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 12ms/step - loss: 0.8311 - accuracy: 0.5072\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.831078052520752, 0.5072202086448669]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGVXMA2yJf1R"
      },
      "source": [
        "implementing word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bN_XxyJKKgH",
        "outputId": "ce824a39-341a-47e0-ae7d-ca487434fd99"
      },
      "source": [
        "# !wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-06 09:35:22--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.98.75\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.98.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  69.2MB/s    in 36s     \n",
            "\n",
            "2021-09-06 09:35:58 (43.7 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7Q4VTzWd3ff"
      },
      "source": [
        "# import gzip\n",
        "# import shutil\n",
        "\n",
        "# with gzip.open(\"GoogleNews-vectors-negative300.bin.gz\", 'rb') as f_in:\n",
        "#   with open(\"GoogleNews-vectors-negative300.bin\", 'wb') as f_out:\n",
        "#     shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4xnv5TQfCux"
      },
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "w2v_model = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/IISc_Assignment/DLNLP_Assignment3/GoogleNews-vectors-negative300.bin\", binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy6klvT3gNDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d74a22-db52-4808-f97f-55e88c86be15"
      },
      "source": [
        "unique_words = len(train_word_index) + 1\n",
        "w2v_embedding_dim = 300\n",
        "w2v_embedding = np.zeros((unique_words, w2v_embedding_dim))\n",
        "\n",
        "for word, i in train_word_index.items():\n",
        "  # if i > num_words:\n",
        "  #   continue\n",
        "  if word in w2v_model.vocab:\n",
        "    embedding = w2v_model.wv[word]\n",
        "\n",
        "  \n",
        "\n",
        "  if embedding is not None:\n",
        "    w2v_embedding[i] = embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCniKX6Lgg1t",
        "outputId": "f8817493-7e6b-4a0a-e974-a57f30f9d2cf"
      },
      "source": [
        "w2v_embedding.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16764, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSNHi2GAiYJC",
        "outputId": "7b789e98-3b97-486b-e3a1-646a6d755801"
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(unique_words, \n",
        "                            output_dim = w2v_embedding_dim,\n",
        "                            weights = [w2v_embedding], trainable = False)\n",
        "\n",
        "model.add(embedding_layer)\n",
        "model.add(LSTM(units=32, dropout=0.2, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IMxdLsBiktm",
        "outputId": "5aba96c4-0443-4ae8-88e2-c559d440389a"
      },
      "source": [
        "model.fit(train_padded_sequences, train_label, epochs=10, verbose = 1, validation_split= 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "225/225 [==============================] - 20s 70ms/step - loss: 0.6697 - accuracy: 0.6251 - val_loss: 0.9368 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "225/225 [==============================] - 16s 70ms/step - loss: 0.6614 - accuracy: 0.6250 - val_loss: 1.0132 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "225/225 [==============================] - 16s 69ms/step - loss: 0.6672 - accuracy: 0.6258 - val_loss: 0.9451 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "225/225 [==============================] - 15s 68ms/step - loss: 0.6557 - accuracy: 0.6250 - val_loss: 0.9238 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "225/225 [==============================] - 16s 69ms/step - loss: 0.7614 - accuracy: 0.6281 - val_loss: 0.8896 - val_accuracy: 0.0344\n",
            "Epoch 6/10\n",
            "225/225 [==============================] - 15s 69ms/step - loss: 0.6471 - accuracy: 0.6393 - val_loss: 0.9156 - val_accuracy: 0.0989\n",
            "Epoch 7/10\n",
            "225/225 [==============================] - 16s 69ms/step - loss: 0.6252 - accuracy: 0.6619 - val_loss: 0.9776 - val_accuracy: 0.1567\n",
            "Epoch 8/10\n",
            "225/225 [==============================] - 16s 70ms/step - loss: 0.5954 - accuracy: 0.6928 - val_loss: 0.8696 - val_accuracy: 0.3172\n",
            "Epoch 9/10\n",
            "225/225 [==============================] - 15s 68ms/step - loss: 0.5298 - accuracy: 0.7079 - val_loss: 0.8198 - val_accuracy: 0.3150\n",
            "Epoch 10/10\n",
            "225/225 [==============================] - 15s 69ms/step - loss: 0.5314 - accuracy: 0.6896 - val_loss: 0.7364 - val_accuracy: 0.2306\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa6903d3950>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PnYBaxkipX5",
        "outputId": "4076cdc4-41b5-4a38-dbea-b6c8b1c2acd9"
      },
      "source": [
        "model.evaluate(test_padded_sequences, test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 12ms/step - loss: 0.7706 - accuracy: 0.4964\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7705963253974915, 0.49638989567756653]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMwn8pRBk7Q_"
      },
      "source": [
        "Implementing Fast Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5RvETsVk_lU",
        "outputId": "08f0084e-22c6-48ac-b9d9-46a7f94e86ce"
      },
      "source": [
        "import gensim.downloader\n",
        "\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGJnR1dPlH47",
        "outputId": "b2940186-2399-4f2b-af28-1afcd5a98ccf"
      },
      "source": [
        "# !pip install fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.7.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpd36Z4LmQCr",
        "outputId": "082e7630-9b07-46e5-87aa-08fbb37bc0f7"
      },
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-06 10:34:57--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.en.300.bin.gz’\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G  32.9MB/s    in 2m 17s  \n",
            "\n",
            "2021-09-06 10:37:14 (31.4 MB/s) - ‘cc.en.300.bin.gz’ saved [4503593528/4503593528]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfM-LlVVqnjk"
      },
      "source": [
        "# import gzip\n",
        "# import shutil\n",
        "\n",
        "# with gzip.open(\"cc.en.300.bin.gz\", 'rb') as f_in:\n",
        "#   with open(\"cc.en.300.bin\", 'wb') as f_out:\n",
        "#     shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU-YcXBhob2h"
      },
      "source": [
        "# import fasttext\n",
        "# from gensim.models import Word2Vec, KeyedVectors\n",
        "# ft_model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/IISc_Assignment/DLNLP_Assignment3/cc.en.300.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBCmrsKQxTDQ",
        "outputId": "98b62fbe-71ae-4176-f6ab-c647c2eced7e"
      },
      "source": [
        "import gensim.downloader\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "if not os.path.isfile('/content/drive/MyDrive/IISc_Assignment/DLNLP_Assignment3/fastText_dict.pkl'):\n",
        "  fastText_embed = gensim.downloader.load('fasttext-wiki-news-subwords-300')\n",
        "  fastText_embedding_dict = open(\"/content/drive/MyDrive/IISc_Assignment/DLNLP_Assignment3/fastText_dict.pkl\", \"wb\")\n",
        "  pickle.dump(fastText_embed, fastText_embedding_dict)\n",
        "  fastText_embedding_dict.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHHJxYzs40Ei"
      },
      "source": [
        "fastText_embed = open(\"/content/drive/MyDrive/IISc_Assignment/DLNLP_Assignment3/fastText_dict.pkl\", \"rb\")\n",
        "fastText_embed_dict = pickle.load(fastText_embed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rTGoI9qqVkp",
        "outputId": "2226e6fd-f3b4-4d50-b5de-1ad812e92ce7"
      },
      "source": [
        "unique_words = len(train_word_index) + 1\n",
        "ft_embedding_dim = 300\n",
        "ft_embedding = np.zeros((unique_words, ft_embedding_dim))\n",
        "\n",
        "for word, i in train_word_index.items():\n",
        "  # if i > num_words:\n",
        "  #   continue\n",
        "  if word in fastText_embed_dict.vocab:\n",
        "    embedding = fastText_embed_dict.wv[word]\n",
        "\n",
        "  \n",
        "\n",
        "  if embedding is not None:\n",
        "    ft_embedding[i] = embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmTMViMwMCHR",
        "outputId": "71684326-6a53-4972-d88f-19760533e840"
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(unique_words, \n",
        "                            output_dim = ft_embedding_dim,\n",
        "                            weights = [ft_embedding], trainable = False)\n",
        "\n",
        "model.add(embedding_layer)\n",
        "model.add(LSTM(units=32, dropout=0.2, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqluAtVoMM9I",
        "outputId": "072c9554-1b87-4087-8a1c-715d055dfd5f"
      },
      "source": [
        "model.fit(train_padded_sequences, train_label, epochs=10, verbose = 1, validation_split= 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "225/225 [==============================] - 18s 63ms/step - loss: 0.6603 - accuracy: 0.6231 - val_loss: 0.9919 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "225/225 [==============================] - 14s 63ms/step - loss: 1.0401 - accuracy: 0.6257 - val_loss: 0.7401 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "225/225 [==============================] - 14s 61ms/step - loss: 0.6723 - accuracy: 0.6250 - val_loss: 0.8280 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "225/225 [==============================] - 14s 61ms/step - loss: 0.6639 - accuracy: 0.6250 - val_loss: 0.8852 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "225/225 [==============================] - 14s 61ms/step - loss: 0.6606 - accuracy: 0.6250 - val_loss: 0.9225 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "225/225 [==============================] - 14s 61ms/step - loss: 0.6592 - accuracy: 0.6250 - val_loss: 0.9469 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "225/225 [==============================] - 14s 62ms/step - loss: 0.6585 - accuracy: 0.6250 - val_loss: 0.9592 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "225/225 [==============================] - 14s 61ms/step - loss: 0.6581 - accuracy: 0.6250 - val_loss: 0.9659 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "225/225 [==============================] - 14s 60ms/step - loss: 0.6577 - accuracy: 0.6250 - val_loss: 0.9702 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "225/225 [==============================] - 14s 62ms/step - loss: 0.6571 - accuracy: 0.6250 - val_loss: 0.9718 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa10269ee50>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_X5mq5tMjLx",
        "outputId": "9a7e2217-3daa-4669-bdd4-31e77f99fd7f"
      },
      "source": [
        "model.evaluate(test_padded_sequences, test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 11ms/step - loss: 0.7253 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.725334644317627, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQXGQ8qjBbR5"
      },
      "source": [
        "Implementing DME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSumB8biBdV7"
      },
      "source": [
        "### DEFINE INPUT LAYER FOR EMBEDDINGS READING AND CONCATENATION ###\n",
        "def Concat_Emb(list_emb, maxlen):\n",
        "    \n",
        "    inputs = []\n",
        "    output = []\n",
        "    for embedding in list_emb:\n",
        "        \n",
        "        inp = Input(shape=(maxlen,))\n",
        "        emb = Embedding(len(train_word_index) + 1, 300, weights=[embedding], trainable=False)(inp)\n",
        "        emb = Reshape((-1,300,1))(emb)\n",
        "        inputs.append(inp)\n",
        "        output.append(emb)\n",
        "        \n",
        "    concat = Concatenate(axis=-1)(output)\n",
        "    \n",
        "    return Model(inputs, concat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs4PGeiNBnP3"
      },
      "source": [
        "def DME(maxlen):\n",
        "    \n",
        "    inp = Input(shape=(maxlen, embedding_dim, no_of_embeddings))\n",
        "    x = Reshape((maxlen, embedding_dim*no_of_embeddings))(inp)    \n",
        "    temp = Dense(embedding_dim*no_of_embeddings,activation=None)(x)\n",
        "    proj2mul  = Reshape((maxlen, embedding_dim,no_of_embeddings))(temp)  \n",
        "    proj = Permute((1,3, 2))(proj2mul)          \n",
        "    alphas = Dense(1,activation=None)(proj)      \n",
        "    alphas = Activation('softmax')(alphas)       \n",
        "    alphas2mul = Permute((1,3, 2)) (alphas)     \n",
        "    x = multiply([proj2mul, alphas2mul])\n",
        "    out = Lambda(lambda t: K.sum(t, axis=-1))(x)\n",
        "    print('Out',out.shape)                     \n",
        "    return Model(inp, out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XDz1aUTFNcY",
        "outputId": "0532b750-8f73-41ad-91ac-fb296749fab4"
      },
      "source": [
        "print(w2v_embedding.shape)\n",
        "print(glove_embedding.shape)\n",
        "print(ft_embedding.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16764, 300)\n",
            "(16764, 300)\n",
            "(16764, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ5aFg5KFgzb"
      },
      "source": [
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5V6Lf6ABwaq",
        "outputId": "17dd16aa-fdbc-4843-b812-b9d73a0ee7c9"
      },
      "source": [
        "embedding_dim = 300\n",
        "no_of_embeddings = 3\n",
        "concat_inp = Concat_Emb([w2v_embedding, ft_embedding, glove_embedding], maxlen=max_len)\n",
        "dme = DME(max_len)\n",
        "x = dme(concat_inp.output)\n",
        "x = GRU(128, dropout=0.2, return_sequences=True)(x)\n",
        "x = GRU(32, dropout=0.2)(x)\n",
        "out = Dense(2, activation='softmax')(x)\n",
        "\n",
        "dme_model = Model(concat_inp.input, out)\n",
        "dme_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out (None, 51, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccqq-fPnCVuC",
        "outputId": "81b54a05-83f2-4493-e03c-5a8109ddb741"
      },
      "source": [
        "dme_model.fit([train_padded_sequences]*no_of_embeddings, train_label, batch_size=64, epochs=10, verbose=1, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "113/113 [==============================] - 15s 54ms/step - loss: 0.6648 - accuracy: 0.6218 - val_loss: 0.9630 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "113/113 [==============================] - 5s 40ms/step - loss: 0.6629 - accuracy: 0.6250 - val_loss: 1.1036 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "113/113 [==============================] - 4s 39ms/step - loss: 0.6630 - accuracy: 0.6251 - val_loss: 0.9762 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 0.6613 - accuracy: 0.6258 - val_loss: 0.9529 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 0.6241 - accuracy: 0.6557 - val_loss: 1.3494 - val_accuracy: 0.2233\n",
            "Epoch 6/10\n",
            "113/113 [==============================] - 5s 40ms/step - loss: 0.4932 - accuracy: 0.7682 - val_loss: 0.5554 - val_accuracy: 0.7678\n",
            "Epoch 7/10\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 0.4010 - accuracy: 0.8200 - val_loss: 0.5995 - val_accuracy: 0.7328\n",
            "Epoch 8/10\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 0.3458 - accuracy: 0.8533 - val_loss: 0.6187 - val_accuracy: 0.7194\n",
            "Epoch 9/10\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 0.2916 - accuracy: 0.8824 - val_loss: 0.5994 - val_accuracy: 0.7489\n",
            "Epoch 10/10\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 0.2548 - accuracy: 0.8972 - val_loss: 0.6589 - val_accuracy: 0.7367\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7de9590dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dqVjmjECaCI",
        "outputId": "628a51c0-09d1-4118-9022-d48b80fa831c"
      },
      "source": [
        "dme_model.evaluate([test_padded_sequences]*no_of_embeddings, test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 18ms/step - loss: 1.3547 - accuracy: 0.4687\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3546805381774902, 0.46871238946914673]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LZrqb8XHR1f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}